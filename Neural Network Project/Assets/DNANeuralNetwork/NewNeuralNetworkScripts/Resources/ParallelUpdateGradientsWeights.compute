// Each #kernel tells which function to compile; you can have many kernels
#pragma kernel CSMain
struct MatrixDimensions
{
    int width;
    int height;
    
    int GetLength()
    {
        return width * height;
    }
};

//Dimensions      Node Values = cost Gradient Bias
RWStructuredBuffer<MatrixDimensions> dimensions; //node Value, inputs, costGradientWeights

//Weighted Inputs
RWStructuredBuffer<double> inputs; //Need to transpose this

//Node Values
RWStructuredBuffer<double> nodeValues;

//Activation
RWStructuredBuffer<double> costGradientWeight;

int NodeIndex(int row, int col)
{
    return row * dimensions[0].width + col;
}

int InputsIndex(int row, int col)
{
    return row * dimensions[1].width + col;
}

///Performs the dot product necessary for the matrix multiplication
double DotProduct(int row, int column, int matrixIndex)
{
    double sum = 0;
     // Perform matrix multiplication
    for (int i = 0; i < dimensions[0].width; ++i)
        sum += nodeValues[matrixIndex * (dimensions[0].GetLength()) + NodeIndex(row, i)] * inputs[matrixIndex * (dimensions[1].GetLength()) + column * dimensions[1].height + i ]; //Correct So far i * dimensions[1].width + column    or InputsIndex(i, column)
    
    return sum;
}

[numthreads(1, 1, 1)]
void CSMain(uint3 DispatchThreadID : SV_DispatchThreadID)
{
    int row = DispatchThreadID.y;
    int col = DispatchThreadID.x;
    int matrixIndex = DispatchThreadID.z;
    
    costGradientWeight[InputsIndex(row, col)] += DotProduct(row, col, matrixIndex); //row * dimensions[2].width + col
}
